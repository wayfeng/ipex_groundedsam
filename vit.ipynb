{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6c60959-9e80-469a-8e34-f6f34602b73b",
   "metadata": {},
   "source": [
    "# Benchmarking ViT with IPEX\n",
    "\n",
    "Pytorch source code and models from: https://github.com/lukemelas/PyTorch-Pretrained-ViT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aea6a1c3-6666-4391-8704-60fa631ca402",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import intel_extension_for_pytorch as ipex\n",
    "\n",
    "from pytorch_pretrained_vit import ViT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "96b716ed-aa52-410e-b304-4f7f9e8122df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import measure_latency, measure_throught"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e7111242-2cf9-492a-b061-ddcf9fa2d604",
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_latency(model, input, niter=100):\n",
    "    # INIT LOGGERS\n",
    "    starter, ender = torch.xpu.Event(enable_timing=True), torch.xpu.Event(enable_timing=True)\n",
    "    timings = np.zeros((niter,1))\n",
    "    #GPU-WARM-UP\n",
    "    for _ in range(10):\n",
    "        _ = model(input)\n",
    "    # MEASURE PERFORMANCE\n",
    "    with torch.no_grad():\n",
    "        for i in range(niter):\n",
    "            starter.record()\n",
    "            _ = model(input)\n",
    "            ender.record()\n",
    "            # WAIT FOR GPU SYNC\n",
    "            torch.xpu.synchronize()\n",
    "            curr_time = starter.elapsed_time(ender)\n",
    "            timings[i] = curr_time\n",
    "    \n",
    "    mean = np.sum(timings) / niter\n",
    "    std = np.std(timings)\n",
    "    return mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c4fb5b07-7b40-4b20-97a8-fff9e4f034af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_throught(model, input, batch_size=1, niter=100):\n",
    "    total_time = 0\n",
    "    with torch.no_grad():\n",
    "        for i in range(niter):\n",
    "            starter, ender = torch.xpu.Event(enable_timing=True), torch.xpu.Event(enable_timing=True)\n",
    "            starter.record()\n",
    "            _ = model(input)\n",
    "            ender.record()\n",
    "            torch.xpu.synchronize()\n",
    "            curr_time = starter.elapsed_time(ender) / 1000\n",
    "            total_time += curr_time\n",
    "    throughput = (niter * batch_size) / total_time\n",
    "    return throughput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d9d0eda-dd0a-4f2e-b9b9-d2a81e188443",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from torchvision import transforms as T\n",
    "\n",
    "img = T.Compose([\n",
    "    T.Resize((384, 384)), \n",
    "    T.ToTensor(),\n",
    "    T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "])(Image.open('./assets/cat_dog.jpeg')).unsqueeze(0)\n",
    "#print(img.shape) # torch.Size([1, 3, 384, 384])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91bbe74d-d065-4522-b943-51be72d65198",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('xpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c6ee54b-6cbd-4a0f-9ca2-8d9817fecca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 384\n",
    "input_data = torch.randn([1,3,input_size,input_size]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ffb0f9ea-e2fc-4b59-83c2-1759e6a4da68",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 128\n",
    "batch_data = torch.randn([bs,3,input_size,input_size]).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b308a5-4600-4496-91d5-efceed042392",
   "metadata": {},
   "source": [
    "### Model Base-patch16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71c8ef28-7d62-4e29-8f5f-473754b201b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights.\n"
     ]
    }
   ],
   "source": [
    "model = ViT('B_16_imagenet1k', pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33e9a9ac-682e-4251-a2b3-9baa30e8f4d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wayne/.env/ov/lib/python3.10/site-packages/intel_extension_for_pytorch/frontend.py:611: UserWarning: Conv BatchNorm folding failed during the optimize process.\n",
      "  warnings.warn(\n",
      "/home/wayne/.env/ov/lib/python3.10/site-packages/intel_extension_for_pytorch/frontend.py:618: UserWarning: Linear BatchNorm folding failed during the optimize process.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "_ = model.eval()\n",
    "model = model.to(device)\n",
    "model = ipex.optimize(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "460706e1-3886-4f4c-9211-d3dccd28ef97",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = img.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e892b03a-4342-4373-ad8e-922db8fbc7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4cfbfdf0-1132-49d7-b754-a87238da5731",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = results.to_tuple()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0dd3d53-1349-4e44-bfc4-d3da31c3fc94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.2 ms ± 754 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit _ = model(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "efd06010-fdf1-4133-a162-9df1e3bd3408",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = torch.xpu.Event(enable_timing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71277d3e-3d8c-4ed2-bb59-e50b0396a893",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22.9734481048584, 0.44333826704895934)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "measure_latency(model, input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e0aa653-b773-4957-85ab-ad5b3b640c87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42.553386870452805"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "measure_throught(model, input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29246f8-cc07-40d6-baeb-2431a0030650",
   "metadata": {},
   "outputs": [],
   "source": [
    "measure_throught(model, input, batch_size=bs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3875a895-134f-4070-aad7-9e5e4bb9b154",
   "metadata": {},
   "source": [
    "#### float16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bec0d44d-6e18-42b9-a629-dc80f599bfdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wayne/.env/ov/lib/python3.10/site-packages/intel_extension_for_pytorch/frontend.py:611: UserWarning: Conv BatchNorm folding failed during the optimize process.\n",
      "  warnings.warn(\n",
      "/home/wayne/.env/ov/lib/python3.10/site-packages/intel_extension_for_pytorch/frontend.py:618: UserWarning: Linear BatchNorm folding failed during the optimize process.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = model.half().eval()\n",
    "model = model.to(device)\n",
    "model = ipex.optimize(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "632feabf-aaae-4eef-bb99-e5386dc6ebf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 384\n",
    "input_data = torch.randn([1,3,input_size,input_size], dtype=torch.float16).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "710b0cc9-661f-4fe1-990f-ae4b7a3dcef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.8 ms ± 75.3 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit _ = model(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2cf4e5bf-9c3a-4ea8-9dd8-256f6576ebb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13.805777060190836, 0.5359536506847442)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "measure_latency(model, input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11676138-1390-4986-9020-8450be3dce19",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 64\n",
    "batch = torch.randn([bs,3,input_size,input_size], dtype=torch.float16).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb987552-1dc1-436d-a3cb-e544b1fd60d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-35.2996321036514"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "measure_throught(model, batch, batch_size=bs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd266753-25ed-4afb-9f42-6ae430d541b9",
   "metadata": {},
   "source": [
    "### Model Base-patch32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "293ab2c6-45df-4f66-af2c-f2b7d920ffd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights.\n"
     ]
    }
   ],
   "source": [
    "model = ViT('B_32_imagenet1k', pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "53cf0a07-cb14-4180-b8cf-6450f86bf32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = model.eval()\n",
    "model = model.to(device)\n",
    "model = ipex.optimize(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "34c9865e-cdcd-42e6-991f-bdd168a32528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.8 ms ± 355 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit _ = model(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5c8d47af-30f3-4a9d-ae63-6344fd23d7bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12.99974452972412, 0.3156719000938009)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "measure_latency(model, input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c79482-c9d9-4fc0-9201-53c8d84a6125",
   "metadata": {},
   "source": [
    "### Model large-patch16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "edde0502-e591-4ed9-b728-4d99118706e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights.\n"
     ]
    }
   ],
   "source": [
    "model = ViT('L_16_imagenet1k', pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7dc3df61-f341-42a1-8215-92b4c7dd9f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wayne/.env/ov/lib/python3.10/site-packages/intel_extension_for_pytorch/frontend.py:611: UserWarning: Conv BatchNorm folding failed during the optimize process.\n",
      "  warnings.warn(\n",
      "/home/wayne/.env/ov/lib/python3.10/site-packages/intel_extension_for_pytorch/frontend.py:618: UserWarning: Linear BatchNorm folding failed during the optimize process.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "_ = model.eval()\n",
    "model = model.to(device)\n",
    "model = ipex.optimize(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6831aa13-e0b0-4b02-abaf-b99b48c198d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40.2 ms ± 4.47 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit _ = model(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f2070c17-12ad-4a50-b8ef-22b01ac60b25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(72.87622802734376, 0.4488054516503352)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "measure_latency(model, input_data, niter=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc03ca7e-e8d0-4e94-b354-8f61b7b7b0ab",
   "metadata": {},
   "source": [
    "#### float16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "223ab77a-e361-427c-8ef3-0d29280acbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.half()\n",
    "#model = model.to(device)\n",
    "#model = ipex.optimize(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c2cf16f3-256a-44d8-8c06-28987f7e31a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#input_size = 384\n",
    "#input_data = torch.randn([1,3,input_size,input_size], dtype=torch.float16).to(device)\n",
    "data = input_data.to(torch.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5651cc91-3715-4725-a4c7-085dd17cc5ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.7 ms ± 710 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit _ = model(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "198d327a-6e13-44ff-bf5b-aa75e0561a7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30.921906077067057, 0.26349938907625875)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "measure_latency(model, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "16d9c8b7-9fa2-4b8f-b68b-97542a76db32",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 32\n",
    "batch = torch.randn([bs,3,input_size,input_size], dtype=torch.float16).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b8a330-847a-4e00-b336-8c47552c7ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "measure_throught(model, batch, batch_size=bs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701758e0-5c7a-43fd-847e-20a639589171",
   "metadata": {},
   "source": [
    "### Model large-patch32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f2a2ccf8-74a4-4465-9cbc-235cecc4c85f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/lukemelas/PyTorch-Pretrained-ViT/releases/download/0.0.2/L_32_imagenet1k.pth\" to /home/wayne/.cache/torch/hub/checkpoints/L_32_imagenet1k.pth\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 1.14G/1.14G [01:38<00:00, 12.4MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights.\n"
     ]
    }
   ],
   "source": [
    "model = ViT('L_32_imagenet1k', pretrained=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
